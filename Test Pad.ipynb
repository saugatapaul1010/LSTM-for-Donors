{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>project_title</th>\n",
       "      <th>price</th>\n",
       "      <th>std_price</th>\n",
       "      <th>nrm_price</th>\n",
       "      <th>presence_of_the_numerical_digits</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>esl_literacy</td>\n",
       "      <td>students english learners working english seco...</td>\n",
       "      <td>educational support english learners home</td>\n",
       "      <td>154.6</td>\n",
       "      <td>-0.390533</td>\n",
       "      <td>0.015397</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fl</td>\n",
       "      <td>mr</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>history_civics_health_sports</td>\n",
       "      <td>civics_government_teamsports</td>\n",
       "      <td>students arrive school eager learn polite gene...</td>\n",
       "      <td>wanted projector hungry learners</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.029839</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 school_state teacher_prefix project_grade_category  \\\n",
       "0           0           in            mrs          grades_prek_2   \n",
       "1           1           fl             mr             grades_6_8   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                             0                    0   \n",
       "1                                             7                    1   \n",
       "\n",
       "               clean_categories           clean_subcategories  \\\n",
       "0             literacy_language                  esl_literacy   \n",
       "1  history_civics_health_sports  civics_government_teamsports   \n",
       "\n",
       "                                               essay  \\\n",
       "0  students english learners working english seco...   \n",
       "1  students arrive school eager learn polite gene...   \n",
       "\n",
       "                               project_title  price  std_price  nrm_price  \\\n",
       "0  educational support english learners home  154.6  -0.390533   0.015397   \n",
       "1           wanted projector hungry learners  299.0   0.002396   0.029839   \n",
       "\n",
       "   presence_of_the_numerical_digits  quantity  \n",
       "0                                 0        23  \n",
       "1                                 0         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"fully_processed_data.csv\", nrows=1000)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_essay=list(data.essay.values)\n",
    "labels=np.array(data.project_is_approved.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9049\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_essay)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_essay = tokens.texts_to_sequences(docs_essay)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "all_lengths=[]\n",
    "for sent in docs_essay:\n",
    "    length=len(sent.split())\n",
    "    all_lengths.append(length)\n",
    "print(max(all_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1   84   45 ...    0    0    0]\n",
      " [   1 1384    2 ...    0    0    0]\n",
      " [ 590 5400    5 ...    0    0    0]\n",
      " ...\n",
      " [  76  610  115 ...    0    0    0]\n",
      " [   1    3  835 ...    0    0    0]\n",
      " [1550 5387 1028 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_essay = pad_sequences(encoded_docs_essay, maxlen=max_length, padding='post')\n",
    "print(padded_docs_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9048/9048 [00:00<00:00, 270988.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n",
      "9049\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "file = open('glove.6B.300d.txt')\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "file.close()\n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "#Create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 300))\n",
    "for word, i in tqdm(tokens.word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector #embedding_matrix.shape: (9049, 300)\n",
    "        \n",
    "print(len(embedding_matrix))\n",
    "print(len(embedding_matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Get the flattened LSTM output for input text\n",
    "input_layer1 = Input(shape=(max_length,))\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=300, weights=[embedding_matrix], input_length=max_length, trainable=False)(input_layer1)\n",
    "lstm_out = LSTM(32, return_sequences=True)(embedding)\n",
    "flatten_lstm_out = Flatten()(lstm_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: school_state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_school_state=list(data.school_state.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_school_state)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_school_state = tokens.texts_to_sequences(docs_school_state)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "all_lengths=[]\n",
    "for sent in docs_school_state:\n",
    "    length=len(sent.split())\n",
    "    all_lengths.append(length)\n",
    "print(max(all_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_school_state = pad_sequences(encoded_docs_school_state, maxlen=max_length, padding='post')\n",
    "#print(padded_docs_school_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the flattened LSTM output for input text\n",
    "input_layer2 = Input(shape=(max_length,))\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=5, input_length=max_length, trainable=True)(input_layer2)\n",
    "flatten_school_state = Flatten()(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: project_grade_category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_project_grade_category=list(data.project_grade_category.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_project_grade_category)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_project_grade_category = tokens.texts_to_sequences(docs_project_grade_category)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_docs_project_grade_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "all_lengths=[]\n",
    "for sent in encoded_docs_project_grade_category:\n",
    "    length=len(sent)\n",
    "    all_lengths.append(length)\n",
    "print(max(all_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 6 7]\n",
      " [1 6 7]\n",
      " ...\n",
      " [1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_project_grade_category = pad_sequences(encoded_docs_project_grade_category, maxlen=max_length, padding='post')\n",
    "print(padded_docs_project_grade_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the flattened LSTM output for input text\n",
    "input_layer3 = Input(shape=(max_length,))\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=5, input_length=max_length, trainable=True)(input_layer3)\n",
    "flatten_project_grade_category = Flatten()(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: clean_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_clean_categories=list(data.clean_categories.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_clean_categories)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_clean_categories = tokens.texts_to_sequences(docs_clean_categories)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_docs_clean_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "all_lengths=[]\n",
    "for sent in encoded_docs_clean_categories:\n",
    "    length=len(sent)\n",
    "    all_lengths.append(length)\n",
    "print(max(all_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  0  0  0]\n",
      " [11 12  5  6  0]\n",
      " [ 5  6  0  0  0]\n",
      " ...\n",
      " [ 1  2  7  0  0]\n",
      " [ 1  2  3  4  0]\n",
      " [ 1  2  7  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_clean_categories = pad_sequences(encoded_docs_clean_categories, maxlen=max_length, padding='post')\n",
    "print(padded_docs_clean_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the flattened LSTM output for input text\n",
    "input_layer4 = Input(shape=(max_length,))\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=5, input_length=max_length, trainable=True)(input_layer4)\n",
    "flatten_clean_categories = Flatten()(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: clean_subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_clean_subcategories=list(data.clean_subcategories.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_clean_subcategories)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_clean_subcategories = tokens.texts_to_sequences(docs_clean_subcategories)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_docs_clean_subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "all_lengths=[]\n",
    "for sent in encoded_docs_clean_subcategories:\n",
    "    length=len(sent)\n",
    "    all_lengths.append(length)\n",
    "print(max(all_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  1  0  0]\n",
      " [30 31 23  0]\n",
      " [ 5  8 23  0]\n",
      " ...\n",
      " [ 1  6  0  0]\n",
      " [ 3  4  2  0]\n",
      " [16  6  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_clean_subcategories = pad_sequences(encoded_docs_clean_subcategories, maxlen=max_length, padding='post')\n",
    "print(padded_docs_clean_subcategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the flattened LSTM output for input text\n",
    "input_layer5 = Input(shape=(max_length,))\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=5, input_length=max_length, trainable=True)(input_layer5)\n",
    "flatten_clean_subcategories = Flatten()(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: teacher_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_teacher_prefix=list(data.teacher_prefix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_teacher_prefix)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_teacher_prefix = tokens.texts_to_sequences(docs_teacher_prefix)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_docs_teacher_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "all_lengths=[]\n",
    "for sent in encoded_docs_teacher_prefix:\n",
    "    length=len(sent)\n",
    "    all_lengths.append(length)\n",
    "print(max(all_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_teacher_prefix = pad_sequences(encoded_docs_teacher_prefix, maxlen=max_length, padding='post')\n",
    "#print(padded_docs_teacher_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the flattened LSTM output for input text\n",
    "input_layer6 = Input(shape=(max_length,))\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=5, input_length=max_length, trainable=True)(input_layer6)\n",
    "flatten_teacher_prefix = Flatten()(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## teacher_number_of_previously_posted_projects, nrm_price, presence_of_the_numerical_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_number_of_previously_posted_projects=list(data.teacher_number_of_previously_posted_projects.values)\n",
    "presence_of_the_numerical_digits=list(data.presence_of_the_numerical_digits.values)\n",
    "nrm_price=list(data.nrm_price.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>presence_of_the_numerical_digits</th>\n",
       "      <th>nrm_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   teacher_number_of_previously_posted_projects  \\\n",
       "0                                             0   \n",
       "1                                             7   \n",
       "2                                             1   \n",
       "3                                             4   \n",
       "4                                             1   \n",
       "\n",
       "   presence_of_the_numerical_digits  nrm_price  \n",
       "0                                 0   0.015397  \n",
       "1                                 0   0.029839  \n",
       "2                                 0   0.051628  \n",
       "3                                 0   0.023228  \n",
       "4                                 0   0.006733  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df=data[['teacher_number_of_previously_posted_projects','presence_of_the_numerical_digits','nrm_price']]\n",
    "numerical_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dense layer\n",
    "input_layer7 = Input(shape=(3,))\n",
    "dense_layer = Dense(3, activation='relu')(input_layer7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation of all the layers and building the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "x = concatenate([flatten_lstm_out, flatten_school_state, flatten_project_grade_category, flatten_clean_categories, flatten_clean_subcategories, flatten_teacher_prefix, dense_layer])\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "output = Dense(1, activation='sigmoid', name='output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.3830\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.2698\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1693\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0750\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0340\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0214\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0088\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0276\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0037\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0086\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0126\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0154\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0027\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0190\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 5.8046e-04\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0129\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0136\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0129\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 4.2130e-04\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 2.0099e-04\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0039\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0079\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.2012e-04\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 2.0339e-04\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 6.9188e-04\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.2809e-04\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 8.4513e-05\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0098\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0019\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 3.5896e-05\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0081\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 3.4467e-04\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 6.0592e-06\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0039\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 4.5638e-04\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 5.7558e-05\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 2.8163e-05\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 2.8566e-04\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0056\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 5.1308e-04\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0064\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 8.7524e-04\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 8.5128e-06\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 3.7393e-06\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.7961e-06\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0122\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0035\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0321\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0090\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 2.2915e-05\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.2581e-06\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0025\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 3.8382e-06\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 2.1238e-04\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0143\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 3.7219e-05\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 7.7506e-07\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0048\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.7131e-06\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 4.5205e-06\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 7.1023e-07\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 3.4628e-07\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0018\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.5088e-04\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0162\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.8372e-07\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 6.7019e-06\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 2.3022e-06\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0019\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0097\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0012\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0021\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0200\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.1456e-04\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 7.3046e-06\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0048\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 6.4467e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 3.6286e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 3.0810e-06\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 4.2039e-04\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 8.3117e-04\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 3.3723e-06\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.4977e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 6.7526e-06\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 4.2866e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 7.7695e-04\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.7581e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 3.1668e-06\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.1971e-07\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.2983e-07\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 7.7874e-06\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 10s 10ms/step - loss: 2.9007e-07\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.8689e-07\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.9090e-07\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 2.0246e-07\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.2149e-07\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.2571e-07\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 2.5450e-07\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.1602e-07\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 1.1602e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc890358780>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputs=[input_layer1,input_layer2,input_layer3,input_layer4,input_layer5,input_layer6,input_layer7], outputs=output)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "model.fit([padded_docs_essay, padded_docs_school_state, padded_docs_project_grade_category, padded_docs_clean_categories, padded_docs_clean_subcategories, padded_docs_teacher_prefix, numerical_df], \n",
    "          [labels],\n",
    "          epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-32fdb01b0fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m loss, accuracy = model.evaluate([padded_docs_essay, padded_docs_school_state, padded_docs_project_grade_category, padded_docs_clean_categories, padded_docs_clean_subcategories, padded_docs_teacher_prefix, numerical_df], \n\u001b[0;32m----> 2\u001b[0;31m           [labels], verbose=0)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate([padded_docs_essay, padded_docs_school_state, padded_docs_project_grade_category, padded_docs_clean_categories, padded_docs_clean_subcategories, padded_docs_teacher_prefix, numerical_df], \n",
    "          [labels], verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "[>                                                           ] 0%\r",
      "[======>                                                     ] 11%\r",
      "Warning: Failed to load file:///mnt/0AD801EDD801D7B9/Donors Assignment/LSTM-for-Donors/custom.css (ignore)\n",
      "[===========================>                                ] 45%\r",
      "[====================================>                       ] 60%\r",
      "[============================================================] 100%\r",
      "Printing pages (2/2)                                               \n",
      "[>                                                           ] \r",
      "Done                                                           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfkit\n",
    "pdfkit.from_file('Test Pad.html', 'Test Pad.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
