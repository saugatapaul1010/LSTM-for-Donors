{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "global start \n",
    "start = dt.now()\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the data and displaying the initial tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the given dataframes.\n",
    "project_data = pd.read_csv('train_data.csv')\n",
    "resource_data = pd.read_csv('resources.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160221</td>\n",
       "      <td>p253737</td>\n",
       "      <td>c90749f5d961ff158d4b4d1e7dc665fc</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>IN</td>\n",
       "      <td>2016-12-05 13:43:57</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>ESL, Literacy</td>\n",
       "      <td>Educational Support for English Learners at Home</td>\n",
       "      <td>My students are English learners that are work...</td>\n",
       "      <td>\\\"The limits of your language are the limits o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need opportunities to practice beg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140945</td>\n",
       "      <td>p258326</td>\n",
       "      <td>897464ce9ddc600bced1151f324dd63a</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-10-25 09:22:10</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>History &amp; Civics, Health &amp; Sports</td>\n",
       "      <td>Civics &amp; Government, Team Sports</td>\n",
       "      <td>Wanted: Projector for Hungry Learners</td>\n",
       "      <td>Our students arrive to our school eager to lea...</td>\n",
       "      <td>The projector we need for our school is very c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need a projector to help with view...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id                        teacher_id teacher_prefix  \\\n",
       "0      160221  p253737  c90749f5d961ff158d4b4d1e7dc665fc           Mrs.   \n",
       "1      140945  p258326  897464ce9ddc600bced1151f324dd63a            Mr.   \n",
       "\n",
       "  school_state project_submitted_datetime project_grade_category  \\\n",
       "0           IN        2016-12-05 13:43:57          Grades PreK-2   \n",
       "1           FL        2016-10-25 09:22:10             Grades 6-8   \n",
       "\n",
       "          project_subject_categories     project_subject_subcategories  \\\n",
       "0                Literacy & Language                     ESL, Literacy   \n",
       "1  History & Civics, Health & Sports  Civics & Government, Team Sports   \n",
       "\n",
       "                                      project_title  \\\n",
       "0  Educational Support for English Learners at Home   \n",
       "1             Wanted: Projector for Hungry Learners   \n",
       "\n",
       "                                     project_essay_1  \\\n",
       "0  My students are English learners that are work...   \n",
       "1  Our students arrive to our school eager to lea...   \n",
       "\n",
       "                                     project_essay_2 project_essay_3  \\\n",
       "0  \\\"The limits of your language are the limits o...             NaN   \n",
       "1  The projector we need for our school is very c...             NaN   \n",
       "\n",
       "  project_essay_4                           project_resource_summary  \\\n",
       "0             NaN  My students need opportunities to practice beg...   \n",
       "1             NaN  My students need a projector to help with view...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \n",
       "0                                             0                    0  \n",
       "1                                             7                    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the contents of \"train_data.csv\"\n",
    "project_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p233245</td>\n",
       "      <td>LC652 - Lakeshore Double-Space Mobile Drying Rack</td>\n",
       "      <td>1</td>\n",
       "      <td>149.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Bouncy Bands for Desks (Blue support pipes)</td>\n",
       "      <td>3</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  quantity  \\\n",
       "0  p233245  LC652 - Lakeshore Double-Space Mobile Drying Rack         1   \n",
       "1  p069063        Bouncy Bands for Desks (Blue support pipes)         3   \n",
       "\n",
       "    price  \n",
       "0  149.00  \n",
       "1   14.95  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the contents of \"resources.csv\"\n",
    "resource_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merge the two dataframes based on ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mrs.</td>\n",
       "      <td>IN</td>\n",
       "      <td>2016-12-05 13:43:57</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>ESL, Literacy</td>\n",
       "      <td>Educational Support for English Learners at Home</td>\n",
       "      <td>My students are English learners that are work...</td>\n",
       "      <td>\\\"The limits of your language are the limits o...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>My students need opportunities to practice beg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154.60</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mr.</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-10-25 09:22:10</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>History &amp; Civics, Health &amp; Sports</td>\n",
       "      <td>Civics &amp; Government, Team Sports</td>\n",
       "      <td>Wanted: Projector for Hungry Learners</td>\n",
       "      <td>Our students arrive to our school eager to lea...</td>\n",
       "      <td>The projector we need for our school is very c...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>My students need a projector to help with view...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ms.</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2016-08-31 12:03:56</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Health &amp; Wellness, Team Sports</td>\n",
       "      <td>Soccer Equipment for AWESOME Middle School Stu...</td>\n",
       "      <td>\\r\\n\\\"True champions aren't always the ones th...</td>\n",
       "      <td>The students on the campus come to school know...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>My students need shine guards, athletic socks,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>516.85</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  teacher_prefix school_state project_submitted_datetime  \\\n",
       "0           Mrs.           IN        2016-12-05 13:43:57   \n",
       "1            Mr.           FL        2016-10-25 09:22:10   \n",
       "2            Ms.           AZ        2016-08-31 12:03:56   \n",
       "\n",
       "  project_grade_category         project_subject_categories  \\\n",
       "0          Grades PreK-2                Literacy & Language   \n",
       "1             Grades 6-8  History & Civics, Health & Sports   \n",
       "2             Grades 6-8                    Health & Sports   \n",
       "\n",
       "      project_subject_subcategories  \\\n",
       "0                     ESL, Literacy   \n",
       "1  Civics & Government, Team Sports   \n",
       "2    Health & Wellness, Team Sports   \n",
       "\n",
       "                                       project_title  \\\n",
       "0   Educational Support for English Learners at Home   \n",
       "1              Wanted: Projector for Hungry Learners   \n",
       "2  Soccer Equipment for AWESOME Middle School Stu...   \n",
       "\n",
       "                                     project_essay_1  \\\n",
       "0  My students are English learners that are work...   \n",
       "1  Our students arrive to our school eager to lea...   \n",
       "2  \\r\\n\\\"True champions aren't always the ones th...   \n",
       "\n",
       "                                     project_essay_2 project_essay_3  \\\n",
       "0  \\\"The limits of your language are the limits o...                   \n",
       "1  The projector we need for our school is very c...                   \n",
       "2  The students on the campus come to school know...                   \n",
       "\n",
       "  project_essay_4                           project_resource_summary  \\\n",
       "0                  My students need opportunities to practice beg...   \n",
       "1                  My students need a projector to help with view...   \n",
       "2                  My students need shine guards, athletic socks,...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved   price  \\\n",
       "0                                             0                    0  154.60   \n",
       "1                                             7                    1  299.00   \n",
       "2                                             1                    0  516.85   \n",
       "\n",
       "   quantity  \n",
       "0        23  \n",
       "1         1  \n",
       "2        22  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging both the dataframes by their corresponding IDs\n",
    "price_quantity_data = resource_data.groupby('id').agg({'price':'sum', 'quantity':'sum'}).reset_index()\n",
    "project_data = pd.merge(project_data, price_quantity_data, on='id', how='left')\n",
    "\n",
    "#Remove the columns which are not needed anymore. Keeping ID for now.\n",
    "project_data.drop(['Unnamed: 0', 'teacher_id', 'id'], axis=1, inplace=True)\n",
    "\n",
    "project_data['teacher_prefix'] = project_data['teacher_prefix'].fillna('Mrs.')\n",
    "project_data['school_state'] = project_data['school_state'].fillna(' ')\n",
    "project_data['project_grade_category'] = project_data['project_grade_category'].fillna(' ')\n",
    "project_data['project_subject_categories'] = project_data['project_subject_categories'].fillna(' ')\n",
    "project_data['project_subject_subcategories'] = project_data['project_subject_subcategories'].fillna(' ')\n",
    "project_data['project_title'] = project_data['project_title'].fillna(' ')\n",
    "project_data['project_essay_1'] = project_data['project_essay_1'].fillna(' ')\n",
    "project_data['project_essay_2'] = project_data['project_essay_2'].fillna(' ')\n",
    "project_data['project_essay_3'] = project_data['project_essay_3'].fillna(' ')\n",
    "project_data['project_essay_4'] = project_data['project_essay_4'].fillna(' ')\n",
    "project_data['project_resource_summary'] = project_data['project_resource_summary'].fillna(' ')\n",
    "project_data['teacher_number_of_previously_posted_projects'] = project_data['teacher_number_of_previously_posted_projects'].fillna(0)\n",
    "project_data['price'] = project_data['price'].fillna(0)\n",
    "project_data['quantity'] = project_data['quantity'].fillna(0)\n",
    "\n",
    "project_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points we have:  109248\n",
      "Number of initial features we have: 16\n",
      "\n",
      "Let's look at the all columns present in the dataset: \n",
      " ['teacher_prefix' 'school_state' 'project_submitted_datetime'\n",
      " 'project_grade_category' 'project_subject_categories'\n",
      " 'project_subject_subcategories' 'project_title' 'project_essay_1'\n",
      " 'project_essay_2' 'project_essay_3' 'project_essay_4'\n",
      " 'project_resource_summary' 'teacher_number_of_previously_posted_projects'\n",
      " 'project_is_approved' 'price' 'quantity']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points we have: \", project_data.shape[0])\n",
    "print(\"Number of initial features we have:\", project_data.shape[1]) \n",
    "print(\"\\nLet's look at the all columns present in the dataset: \\n\",project_data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Pre-processing Section\n",
    "\n",
    "In this section, we will pre-process all the data before using them to build Machine Learning models. The dataset has the following types of features:\n",
    "\n",
    "<b>Categorical variables:</b>\n",
    "\n",
    "1. teacher_prefix\n",
    "2. school_state\n",
    "3. project_grade_category\n",
    "4. project_subject_categories\n",
    "5. project_subject_subcategories\n",
    "\n",
    "<b>Text data:</b>\n",
    "\n",
    "1. project_essay_1\n",
    "2. project_essay_2\n",
    "3. project_essay_3\n",
    "4. project_essay_4\n",
    "5. project_title\n",
    "6. project_resource_summary\n",
    "\n",
    "<b>Numerical Data:</b>\n",
    "\n",
    "1. teacher_number_of_previously_posted_projects\n",
    "2. price\n",
    "3. quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Utility functions for pre processing text datas and categories data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopwords contains the list of commonly found english keywords. We will remove them from the text datas as part of the pre-processing of data.\n",
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\",\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\", \\\n",
    "            't','u','v','w','x','y','z']\n",
    "\n",
    "from tqdm import tqdm\n",
    "def clean_subjects(input_values):\n",
    "    '''This function will be used to pre process the two features -> \"project_subject_categories\" and \n",
    "    \"project_subject_subcategories\"'''\n",
    "    processed_list = []\n",
    "    for i in tqdm(input_values):\n",
    "        temp = \"\"\n",
    "        for j in i.split(','):\n",
    "            if 'The' in j.split(): \n",
    "                j=j.replace('The','') \n",
    "            j = j.replace(' ','') \n",
    "            temp +=j.strip()+\" \"\n",
    "            temp = temp.replace('&','_')\n",
    "        processed_list.append(temp.strip())\n",
    "    return processed_list\n",
    "\n",
    "import re\n",
    "def decontracted(phrase):\n",
    "    \"\"\"This function will be used to expand the de-contracted words\"\"\"\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def process_text(list_of_sentences):\n",
    "    \"\"\"This function will be used to pre-process the text data\"\"\"\n",
    "    preprocessed_texts = []\n",
    "    for sentence in tqdm(list_of_sentences):\n",
    "        sent = decontracted(sentence)\n",
    "        sent = sent.replace('\\\\r', ' ')\n",
    "        sent = sent.replace('\\\\\"', ' ')\n",
    "        sent = sent.replace('\\\\n', ' ')\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "        sent = ' '.join(word.lower() for word in sent.split() if word.lower() not in stopwords) #We will keep only those words in title which has a string length greater than one\n",
    "        preprocessed_texts.append(sent.lower().strip())\n",
    "    return preprocessed_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Pre-Processing the 'essays' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109248/109248 [02:00<00:00, 905.36it/s]\n"
     ]
    }
   ],
   "source": [
    "#Merging the essays data into one single column for ease of processing.\n",
    "project_data[\"essay\"] = project_data[\"project_essay_1\"].map(str) + \\\n",
    "                        project_data[\"project_essay_2\"].map(str) + \\\n",
    "                        project_data[\"project_essay_3\"].map(str) + \\\n",
    "                        project_data[\"project_essay_4\"].map(str)\n",
    "\n",
    "preprocessed_essays = process_text(project_data[\"essay\"].values)\n",
    "\n",
    "#Add the pre-processed data into a new column.\n",
    "project_data['clean_essays'] = preprocessed_essays\n",
    "\n",
    "#Remove the columns which are already processed and are not needed anymore.\n",
    "project_data.drop(['essay','project_essay_1','project_essay_2','project_essay_3','project_essay_4'], \n",
    "                  axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Pre-Processing the 'project_resource_summary' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109248/109248 [00:12<00:00, 8621.78it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_summary = process_text(project_data['project_resource_summary'].values)\n",
    "project_data['clean_project_resource_summary'] = preprocessed_summary\n",
    "project_data.drop(['project_resource_summary'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Pre-Processing the 'project_title' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109248/109248 [00:05<00:00, 19912.64it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_titles = process_text(project_data['project_title'].values)\n",
    "project_data['clean_project_title'] = preprocessed_titles\n",
    "project_data.drop(['project_title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Pre-Processing of 'project_subject_categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109248/109248 [00:00<00:00, 302094.48it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_categories = clean_subjects(project_data['project_subject_categories'].values)\n",
    "\n",
    "project_data['clean_categories'] = preprocessed_categories\n",
    "project_data.drop(['project_subject_categories'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Pre-Processing of 'project_subject_subcategories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109248/109248 [00:00<00:00, 301790.06it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_subcategories = clean_subjects(project_data['project_subject_subcategories'].values)\n",
    "\n",
    "project_data['clean_subcategories'] = preprocessed_subcategories\n",
    "project_data.drop(['project_subject_subcategories'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Pre-Processing of 'project_grade_category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['project_grade_category'] = project_data['project_grade_category'].map(lambda x: x.replace(\" \",\"_\").replace(\"-\",\"_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Designing a new feature called - Presence of numerical digits in project resources summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_digit(sent):\n",
    "    digits=re.findall('\\d+', sent)\n",
    "    if(len(digits) != 0 ):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "project_data['presence_of_the_numerical_digits']=project_data['clean_project_resource_summary'].apply(is_digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Combining all text features into one single feature 'total_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['total_text'] = project_data['clean_essays'].map(str) + \" \" + project_data['clean_project_resource_summary'].map(str) + \" \" + project_data['clean_project_title'].map(str)\n",
    "project_data.drop(['clean_essays','clean_project_resource_summary','clean_project_title','project_submitted_datetime'], axis=1, inplace=True) #Remove not needed features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9 Replacing NAN values by empty strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['teacher_prefix'] = project_data['teacher_prefix'].fillna('Mrs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.10 Display the processed dataframe and save it into a pandas CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>presence_of_the_numerical_digits</th>\n",
       "      <th>total_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mrs.</td>\n",
       "      <td>IN</td>\n",
       "      <td>Grades_PreK_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154.60</td>\n",
       "      <td>23</td>\n",
       "      <td>Literacy_Language</td>\n",
       "      <td>ESL Literacy</td>\n",
       "      <td>0</td>\n",
       "      <td>students english learners working english seco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mr.</td>\n",
       "      <td>FL</td>\n",
       "      <td>Grades_6_8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1</td>\n",
       "      <td>History_Civics Health_Sports</td>\n",
       "      <td>Civics_Government TeamSports</td>\n",
       "      <td>0</td>\n",
       "      <td>students arrive school eager learn polite gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ms.</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Grades_6_8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>516.85</td>\n",
       "      <td>22</td>\n",
       "      <td>Health_Sports</td>\n",
       "      <td>Health_Wellness TeamSports</td>\n",
       "      <td>0</td>\n",
       "      <td>true champions not always ones win guts mia ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mrs.</td>\n",
       "      <td>KY</td>\n",
       "      <td>Grades_PreK_2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>232.90</td>\n",
       "      <td>4</td>\n",
       "      <td>Literacy_Language Math_Science</td>\n",
       "      <td>Literacy Mathematics</td>\n",
       "      <td>0</td>\n",
       "      <td>work unique school filled esl english second l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mrs.</td>\n",
       "      <td>TX</td>\n",
       "      <td>Grades_PreK_2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67.98</td>\n",
       "      <td>4</td>\n",
       "      <td>Math_Science</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>0</td>\n",
       "      <td>second grade classroom next year made around 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  teacher_prefix school_state project_grade_category  \\\n",
       "0           Mrs.           IN          Grades_PreK_2   \n",
       "1            Mr.           FL             Grades_6_8   \n",
       "2            Ms.           AZ             Grades_6_8   \n",
       "3           Mrs.           KY          Grades_PreK_2   \n",
       "4           Mrs.           TX          Grades_PreK_2   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved   price  \\\n",
       "0                                             0                    0  154.60   \n",
       "1                                             7                    1  299.00   \n",
       "2                                             1                    0  516.85   \n",
       "3                                             4                    1  232.90   \n",
       "4                                             1                    1   67.98   \n",
       "\n",
       "   quantity                clean_categories           clean_subcategories  \\\n",
       "0        23               Literacy_Language                  ESL Literacy   \n",
       "1         1    History_Civics Health_Sports  Civics_Government TeamSports   \n",
       "2        22                   Health_Sports    Health_Wellness TeamSports   \n",
       "3         4  Literacy_Language Math_Science          Literacy Mathematics   \n",
       "4         4                    Math_Science                   Mathematics   \n",
       "\n",
       "   presence_of_the_numerical_digits  \\\n",
       "0                                 0   \n",
       "1                                 0   \n",
       "2                                 0   \n",
       "3                                 0   \n",
       "4                                 0   \n",
       "\n",
       "                                          total_text  \n",
       "0  students english learners working english seco...  \n",
       "1  students arrive school eager learn polite gene...  \n",
       "2  true champions not always ones win guts mia ha...  \n",
       "3  work unique school filled esl english second l...  \n",
       "4  second grade classroom next year made around 2...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After pre-processing, we have 13 features. We will have one feature as our target variable and the rest of the columns as our independent features variables.\n",
    "project_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the processed dataset into a pandas CSV file.\n",
    "project_data.to_csv(\"processed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = pd.read_csv(\"processed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Splitting the original data into train and test data in 80:20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in train data:  87398\n",
      "Number of points in validation data:  21850\n"
     ]
    }
   ],
   "source": [
    "#Taking the target and predictor variables into separate variables\n",
    "y = project_data[\"project_is_approved\"] #target variables\n",
    "X = project_data.drop(['project_is_approved'], axis=1) #predictor variables\n",
    "\n",
    "#Split the dataset into train and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1, stratify=y)\n",
    "\n",
    "#Display basic information after splitting the data\n",
    "print(\"Number of points in train data: \",X_train.shape[0])\n",
    "print(\"Number of points in validation data: \",X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the total_text values in list\n",
    "docs_text_train=list(X_train.total_text.values)\n",
    "docs_text_test=list(X_test.total_text.values)\n",
    "labels_train=np.array(y_train)\n",
    "labels_test=np.array(y_test)\n",
    "\n",
    "#Initializing the keras tokenizer and fitting it on train data\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_text_train)\n",
    "\n",
    "#Convert the texts to sequences using the tokenizer\n",
    "sequences_text_train = tokens.texts_to_sequences(docs_text_train)\n",
    "sequences_text_test = tokens.texts_to_sequences(docs_text_test)\n",
    "vocab_size_text = len(tokens.word_index) + 1\n",
    "\n",
    "#Add padding\n",
    "padded_text_train = pad_sequences(sequences_text_train, maxlen=300, padding='post')\n",
    "padded_text_test = pad_sequences(sequences_text_test, maxlen=300, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55638/55638 [00:00<00:00, 301621.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "file = open('glove.6B.300d.txt')\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "file.close()\n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "#Create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size_text, 300))\n",
    "for word, i in tqdm(tokens.word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector #embedding_matrix.shape: (9049, 300)\n",
    "\n",
    "print(len(embedding_matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Get the flattened LSTM output for input text\n",
    "input_layer_total_text = Input(shape=(300,), name = \"total_text_sequence\")\n",
    "embedding_layer_total_text = Embedding(input_dim=vocab_size_text, output_dim=300, weights=[embedding_matrix], trainable=False)(input_layer_total_text)\n",
    "lstm_total_text  = LSTM(16, activation=\"relu\", return_sequences=True)(embedding_layer_total_text)\n",
    "flatten_total_text = Flatten()(lstm_total_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: school_state "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the school state values\n",
    "docs_school_state_train=list(X_train.school_state.values)\n",
    "docs_school_state_test=list(X_test.school_state.values)\n",
    "\n",
    "#Initializing the keras tokenizer and fitting it on train data\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_school_state_train)\n",
    "\n",
    "#Convert the school_state to sequences using the tokenizer\n",
    "sequences_school_train = np.array(tokens.texts_to_sequences(docs_school_state_train))\n",
    "sequences_school_test = np.array(tokens.texts_to_sequences(docs_school_state_test))\n",
    "vocab_size_school_state = len(tokens.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the flattened output for school_state\n",
    "input_layer_school_state = Input(shape=(1,), name = \"encoded_school_state\")\n",
    "embedding_layer_school_state = Embedding(input_dim=vocab_size_school_state, output_dim=4, trainable=True)(input_layer_school_state)\n",
    "flatten_school_state = Flatten()(embedding_layer_school_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: teacher_prefix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the teacher_prefix values\n",
    "docs_teacher_prefix_train=list(X_train.teacher_prefix.values)\n",
    "docs_teacher_prefix_test=list(X_test.teacher_prefix.values)\n",
    "\n",
    "#Initializing the keras tokenizer and fitting it on train data\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_teacher_prefix_train)\n",
    "\n",
    "#Convert the school_state to sequences using the tokenizer\n",
    "sequences_teacher_prefix_train = np.array(tokens.texts_to_sequences(docs_teacher_prefix_train))\n",
    "sequences_teacher_prefix_test = np.array(tokens.texts_to_sequences(docs_teacher_prefix_test))\n",
    "vocab_size_teacher_prefix = len(tokens.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher_prefix\n",
    "input_layer_teacher_prefix = Input(shape=(1,), name = \"teacher_prefix\")\n",
    "embedding_layer_teacher_prefix = Embedding(input_dim=vocab_size_teacher_prefix, output_dim=4, trainable=True)(input_layer_teacher_prefix)\n",
    "flatten_teacher_prefix = Flatten()(embedding_layer_teacher_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: project_grade_category "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the project_grade_category values\n",
    "docs_project_grade_category_train=list(X_train.project_grade_category.values)\n",
    "docs_project_grade_category_test=list(X_test.project_grade_category.values)\n",
    "\n",
    "#Initializing the keras tokenizer and fitting it on train data\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_project_grade_category_train)\n",
    "\n",
    "#Convert the school_state to sequences using the tokenizer\n",
    "sequences_project_grade_category_train = tokens.texts_to_sequences(docs_project_grade_category_train)\n",
    "sequences_project_grade_category_test = tokens.texts_to_sequences(docs_project_grade_category_test)\n",
    "vocab_size_project_grade_category= len(tokens.word_index) + 1\n",
    "\n",
    "#Add padding\n",
    "padded_project_grade_category_train = pad_sequences(sequences_project_grade_category_train, maxlen=3, padding='post')\n",
    "padded_project_grade_category_test = pad_sequences(sequences_project_grade_category_test, maxlen=3, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_grade_category\n",
    "input_layer_project_grade = Input(shape=(3,), name = \"project_grade_category\")\n",
    "embedding_layer_project_grade = Embedding(input_dim=vocab_size_project_grade_category, output_dim=4, trainable=True)(input_layer_project_grade)\n",
    "flatten_project_grade = Flatten()(embedding_layer_project_grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: clean_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the clean_categories values\n",
    "docs_clean_categories_train=list(X_train.clean_categories.values)\n",
    "docs_clean_categories_test=list(X_test.clean_categories.values)\n",
    "\n",
    "#Initializing the keras tokenizer and fitting it on train data\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_clean_categories_train)\n",
    "\n",
    "#Convert the school_state to sequences using the tokenizer\n",
    "sequences_clean_categories_train = tokens.texts_to_sequences(docs_clean_categories_train)\n",
    "sequences_clean_categories_test = tokens.texts_to_sequences(docs_clean_categories_test)\n",
    "vocab_size_clean_categories = len(tokens.word_index) + 1\n",
    "\n",
    "#Add padding\n",
    "padded_clean_categories_train = pad_sequences(sequences_clean_categories_train, maxlen=3, padding='post')\n",
    "padded_clean_categories_test = pad_sequences(sequences_clean_categories_test, maxlen=3, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_categories\n",
    "input_layer_clean_categories = Input(shape=(3,), name = \"clean_categories\")\n",
    "embedding_layer_clean_categories = Embedding(input_dim=vocab_size_clean_categories, output_dim=4, trainable=True)(input_layer_clean_categories)\n",
    "flatten_clean_categories = Flatten()(embedding_layer_clean_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: clean_subcategories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the clean_subcategories values\n",
    "docs_clean_subcategories_train=list(X_train.clean_subcategories.values)\n",
    "docs_clean_subcategories_test=list(X_test.clean_subcategories.values)\n",
    "\n",
    "#Initializing the keras tokenizer and fitting it on train data\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_clean_subcategories_train)\n",
    "\n",
    "#Convert the school_state to sequences using the tokenizer\n",
    "sequences_clean_subcategories_train = tokens.texts_to_sequences(docs_clean_subcategories_train)\n",
    "sequences_clean_subcategories_test = tokens.texts_to_sequences(docs_clean_subcategories_test)\n",
    "vocab_size_clean_subcategories = len(tokens.word_index) + 1\n",
    "\n",
    "padded_clean_subcategories_train = pad_sequences(sequences_clean_subcategories_train, maxlen=3, padding='post')\n",
    "padded_clean_subcategories_test = pad_sequences(sequences_clean_subcategories_test, maxlen=3, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_subcategories\n",
    "input_layer_clean_subcategories = Input(shape=(3,), name = \"clean_subcategories\")\n",
    "embedding_layer_clean_subcategories = Embedding(input_dim=vocab_size_clean_subcategories, output_dim=4, trainable=True)(input_layer_clean_subcategories)\n",
    "flatten_clean_subcategories = Flatten()(embedding_layer_clean_subcategories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def normalize_vars(data):\n",
    "    \"\"\"This function is used to normalize all the input datas between 0 and 1\"\"\"\n",
    "    normalizer = Normalizer()\n",
    "    data_normalized = normalizer.fit_transform(data.reshape(1, -1))\n",
    "    return data_normalized, normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## teacher_number_of_previously_posted_projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_projects_train = X_train.teacher_number_of_previously_posted_projects.values\n",
    "previous_projects_test = X_test.teacher_number_of_previously_posted_projects.values\n",
    "\n",
    "norm_previous_projects_train, normalizer = normalize_vars(previous_projects_train.reshape(1,-1))\n",
    "norm_previous_projects_test = normalizer.transform(previous_projects_test.reshape(1,-1))\n",
    "\n",
    "norm_previous_projects_train = norm_previous_projects_train.reshape(len(X_train),1)\n",
    "norm_previous_projects_test = norm_previous_projects_test.reshape(len(X_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_previous_projects = Input(shape=(1,), name = \"previous_projects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_train = X_train.price.values\n",
    "price_test = X_test.price.values\n",
    "\n",
    "norm_price_train, normalizer = normalize_vars(price_train.reshape(1,-1))\n",
    "norm_price_test = normalizer.transform(price_test.reshape(1,-1))\n",
    "\n",
    "norm_price_train = norm_price_train.reshape(len(X_train),1)\n",
    "norm_price_test = norm_price_test.reshape(len(X_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_price = Input(shape=(1,), name = \"price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_train = X_train.quantity.values\n",
    "quantity_test = X_test.quantity.values\n",
    "\n",
    "norm_quantity_train, normalizer = normalize_vars(quantity_train.reshape(1,-1))\n",
    "norm_quantity_test = normalizer.transform(quantity_test.reshape(1,-1))\n",
    "\n",
    "norm_quantity_train = norm_quantity_train.reshape(len(X_train),1)\n",
    "norm_quantity_test = norm_quantity_test.reshape(len(X_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_quantity = Input(shape=(1,), name = \"quantity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation of all the numerical features layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features_layers_concat = concatenate([input_layer_previous_projects, input_layer_price, input_layer_quantity])\n",
    "dense_layer_numerical = Dense(4, activation='relu',kernel_initializer='he_normal')(numerical_features_layers_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation of all the layers and building the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "total_text_sequence (InputLayer (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 300, 300)     16691700    total_text_sequence[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "teacher_prefix (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoded_school_state (InputLaye (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "project_grade_category (InputLa (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clean_categories (InputLayer)   (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clean_subcategories (InputLayer (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "previous_projects (InputLayer)  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "price (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "quantity (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 300, 16)      20288       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 4)         24          teacher_prefix[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 4)         208         encoded_school_state[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 3, 4)         40          project_grade_category[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 3, 4)         64          clean_categories[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 3, 4)         152         clean_subcategories[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3)            0           previous_projects[0][0]          \n",
      "                                                                 price[0][0]                      \n",
      "                                                                 quantity[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4800)         0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 4)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 4)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 12)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 12)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 12)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            16          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4848)         0           flatten_1[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer_1 (Dense)           (None, 8)            38792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8)            0           dense_layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer_2 (Dense)           (None, 4)            36          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4)            0           dense_layer_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            5           dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,751,325\n",
      "Trainable params: 59,625\n",
      "Non-trainable params: 16,691,700\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Merge all the layers according to the architecture diagram\n",
    "x = concatenate([flatten_total_text, flatten_teacher_prefix, flatten_school_state, flatten_project_grade, flatten_clean_categories, flatten_clean_subcategories, dense_layer_numerical])\n",
    "x = Dense(8, activation='relu',kernel_initializer='he_normal', name='dense_layer_1')(x)\n",
    "x = Dropout(0.6, name='dropout_1')(x)\n",
    "x = Dense(4, activation='relu',kernel_initializer='he_normal',name='dense_layer_2')(x)\n",
    "x = Dropout(0.6, name='dropout_2')(x)\n",
    "output_layer = Dense(1, activation='sigmoid', name='output_layer')(x)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=[input_layer_total_text,input_layer_teacher_prefix,input_layer_school_state,input_layer_project_grade,input_layer_clean_categories,\n",
    "                      input_layer_clean_subcategories,input_layer_previous_projects,input_layer_price,input_layer_quantity], outputs=[output_layer])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a custom metric AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as sklm\n",
    "import tensorflow as tf\n",
    "def auc_roc(y_true, y_pred):\n",
    "    return tf.py_func(sklm.roc_auc_score, (y_true, y_pred), tf.double)\n",
    "\n",
    "import keras\n",
    "#https://stackoverflow.com/questions/51922500/tf-metrics-auc-yielding-very-different-from-sklearn-metrics-roc-auc-score\n",
    "def roc_auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, EarlyStopping\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time))\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto', baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87398 samples, validate on 21850 samples\n",
      "Epoch 1/50\n",
      "87398/87398 [==============================] - 140s 2ms/step - loss: 0.5275 - roc_auc: 0.5134 - val_loss: 0.4492 - val_roc_auc: 0.5350\n",
      "Epoch 2/50\n",
      "87398/87398 [==============================] - 134s 2ms/step - loss: 0.4905 - roc_auc: 0.5507 - val_loss: 0.4232 - val_roc_auc: 0.5634\n",
      "Epoch 3/50\n",
      "87398/87398 [==============================] - 135s 2ms/step - loss: 0.4702 - roc_auc: 0.5720 - val_loss: 0.3959 - val_roc_auc: 0.5801\n",
      "Epoch 4/50\n",
      "87398/87398 [==============================] - 134s 2ms/step - loss: 0.4548 - roc_auc: 0.5868 - val_loss: 0.3864 - val_roc_auc: 0.5926\n",
      "Epoch 5/50\n",
      "87398/87398 [==============================] - 133s 2ms/step - loss: 0.4452 - roc_auc: 0.5971 - val_loss: 0.3948 - val_roc_auc: 0.6008\n",
      "Epoch 6/50\n",
      "87398/87398 [==============================] - 133s 2ms/step - loss: 0.4354 - roc_auc: 0.6043 - val_loss: 0.3848 - val_roc_auc: 0.6077\n",
      "Epoch 7/50\n",
      "17408/87398 [====>.........................] - ETA: 1:33 - loss: 0.4309 - roc_auc: 0.6095"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[roc_auc])\n",
    "model.fit(x=[padded_text_train,sequences_teacher_prefix_train,sequences_school_train,padded_project_grade_category_train,padded_clean_categories_train,padded_clean_subcategories_train,\n",
    "             norm_previous_projects_train,norm_price_train,norm_quantity_train], \n",
    "          y=[labels_train],\n",
    "          validation_data=([padded_text_test,sequences_teacher_prefix_test,sequences_school_test,padded_project_grade_category_test,padded_clean_categories_test,padded_clean_subcategories_test,\n",
    "                            norm_previous_projects_test,norm_price_test,norm_quantity_test],[labels_test]),\n",
    "          epochs=50, \n",
    "          batch_size=1024, \n",
    "          callbacks=[tensorboard,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train the TF-IDF on the Train data <br>\n",
    "2. Get the idf value for each word we have in the train data. <br>\n",
    "3. Remove the low idf value and high idf value words from our data. Do some analysis on the Idf values and based on those values choose the low and high threshold value. Because very frequent words and very very rare words don't give much information. (you can plot a box plots and take only the idf scores within IQR range and corresponding words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Fit the TFIDF vectorizer to the train data\n",
    "vect = TfidfVectorizer()\n",
    "vect.fit_transform(X_train['total_text'])\n",
    "\n",
    "#Get the features names and their corresponding IDF scores\n",
    "words = vect.get_feature_names()\n",
    "idf_words = vect.idf_\n",
    "\n",
    "#Map the words and their idf_ scores in a disctionary\n",
    "dict_word_idf_ = dict(zip(words, idf_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box-Plot Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lowest significant value of TF-IDF Scores:  9.739181790315316\n",
      "The highest significant value of TF-IDF Scores:  11.685091939370627\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.boxplot(idf_words)\n",
    "plt.title('Box Plot Analysis')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('IDF Score')\n",
    "plt.show()\n",
    "\n",
    "p_25th = np.percentile(idf_words,25)\n",
    "p_75th = np.percentile(idf_words,75)\n",
    "\n",
    "print(\"The lowest significant value of TF-IDF Scores: \",p_25th)\n",
    "print(\"The highest significant value of TF-IDF Scores: \",p_75th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of words to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words to be removed:  13786\n"
     ]
    }
   ],
   "source": [
    "removed_wordlist = []\n",
    "for word in list(dict_word_idf_.keys()):\n",
    "    if(dict_word_idf_[word] < p_25th or dict_word_idf_[word] > p_75th):\n",
    "        removed_wordlist.append(word)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "print(\"Number of words to be removed: \",len(removed_wordlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
