{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>project_title</th>\n",
       "      <th>price</th>\n",
       "      <th>std_price</th>\n",
       "      <th>nrm_price</th>\n",
       "      <th>presence_of_the_numerical_digits</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>literacy language</td>\n",
       "      <td>esl literacy</td>\n",
       "      <td>students english learners working english seco...</td>\n",
       "      <td>educational support english learners home</td>\n",
       "      <td>154.6</td>\n",
       "      <td>-0.390533</td>\n",
       "      <td>0.015397</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fl</td>\n",
       "      <td>mr</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>history civics health sports</td>\n",
       "      <td>civics government team sports</td>\n",
       "      <td>students arrive school eager learn polite gene...</td>\n",
       "      <td>wanted projector hungry learners</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.029839</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 school_state teacher_prefix project_grade_category  \\\n",
       "0           0           in            mrs          grades_prek_2   \n",
       "1           1           fl             mr             grades_6_8   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                             0                    0   \n",
       "1                                             7                    1   \n",
       "\n",
       "               clean_categories            clean_subcategories  \\\n",
       "0             literacy language                   esl literacy   \n",
       "1  history civics health sports  civics government team sports   \n",
       "\n",
       "                                               essay  \\\n",
       "0  students english learners working english seco...   \n",
       "1  students arrive school eager learn polite gene...   \n",
       "\n",
       "                               project_title  price  std_price  nrm_price  \\\n",
       "0  educational support english learners home  154.6  -0.390533   0.015397   \n",
       "1           wanted projector hungry learners  299.0   0.002396   0.029839   \n",
       "\n",
       "   presence_of_the_numerical_digits  quantity  \n",
       "0                                 0        23  \n",
       "1                                 0         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"fully_processed_data.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=data.drop('project_is_approved', axis=1)\n",
    "y=data['project_is_approved']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_essay_train=list(X_train.essay.values)\n",
    "labels_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51537\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_essay_train)\n",
    "vocab_size_train = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_essay_train = tokens.texts_to_sequences(docs_essay_train)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "all_lengths=[]\n",
    "for sent in docs_essay_train:\n",
    "    length=len(sent.split())\n",
    "    all_lengths.append(length)\n",
    "print(max(all_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  41  100  170 ...    0    0    0]\n",
      " [ 538  489 3840 ...    0    0    0]\n",
      " [ 173   72  651 ...    0    0    0]\n",
      " ...\n",
      " [   1   86  534 ...    0    0    0]\n",
      " [ 788 4659    4 ...    0    0    0]\n",
      " [5403 8112 9655 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_essay_train = pad_sequences(encoded_docs_essay_train, maxlen=max_length, padding='post')\n",
    "print(padded_docs_essay_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51536/51536 [00:00<00:00, 284795.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n",
      "51537\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "file = open('glove.6B.300d.txt')\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "file.close()\n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "#Create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size_train, 300))\n",
    "for word, i in tqdm(tokens.word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector #embedding_matrix.shape: (9049, 300)\n",
    "        \n",
    "print(len(embedding_matrix))\n",
    "print(len(embedding_matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Get the flattened LSTM output for input text\n",
    "input_layer1 = Input(shape=(max_length,))\n",
    "embedding = Embedding(input_dim=vocab_size_train, output_dim=300, weights=[embedding_matrix], input_length=max_length, trainable=False)(input_layer1)\n",
    "lstm_out = LSTM(32, return_sequences=True)(embedding)\n",
    "flatten_lstm_out = Flatten()(lstm_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_essay_test=list(X_test.essay.values)\n",
    "labels_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30232\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_essay_test)\n",
    "vocab_size_test = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_essay_test = tokens.texts_to_sequences(docs_essay_test)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  592  460 ...    0    0    0]\n",
      " [  68   78  122 ...    0    0    0]\n",
      " [ 170    5    6 ...    0    0    0]\n",
      " ...\n",
      " [   1 1188    6 ...    0    0    0]\n",
      " [   2  670  260 ...    0    0    0]\n",
      " [  63   31    1 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "#Pad documents to a max length\n",
    "padded_docs_essay_test = pad_sequences(encoded_docs_essay_test, maxlen=max_length, padding='post')\n",
    "print(padded_docs_essay_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: school_state "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_school_state_train=list(X_train.school_state.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_school_state_train)\n",
    "vocab_size_train = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_school_state_train = tokens.texts_to_sequences(docs_school_state_train)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "all_lengths=[]\n",
    "for sent in docs_school_state_train:\n",
    "    length=len(sent.split())\n",
    "    all_lengths.append(length)\n",
    "print(max(all_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_school_state_train = pad_sequences(encoded_docs_school_state_train, maxlen=max_length, padding='post')\n",
    "#print(padded_docs_school_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the flattened LSTM output for input text\n",
    "input_layer2 = Input(shape=(max_length,))\n",
    "embedding = Embedding(input_dim=vocab_size_train, output_dim=5, input_length=max_length, trainable=True)(input_layer2)\n",
    "flatten_school_state = Flatten()(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_school_state_test=list(X_test.school_state.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_school_state_test)\n",
    "vocab_size_test = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_school_state_test = tokens.texts_to_sequences(docs_school_state_test)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "padded_docs_school_state_test = pad_sequences(encoded_docs_school_state_test, maxlen=max_length, padding='post')\n",
    "#print(padded_docs_school_state_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: project_grade_category "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_project_grade_category_train=list(X_train.project_grade_category.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_project_grade_category_train)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_project_grade_category_train = tokens.texts_to_sequences(docs_project_grade_category_train)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "all_lengths=[]\n",
    "for sent in docs_project_grade_category_train:\n",
    "    length=len(sent)\n",
    "    all_lengths.append(length)\n",
    "print(max(all_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4 5 ... 0 0 0]\n",
      " [1 4 5 ... 0 0 0]\n",
      " [1 4 5 ... 0 0 0]\n",
      " ...\n",
      " [1 2 3 ... 0 0 0]\n",
      " [1 4 5 ... 0 0 0]\n",
      " [1 2 3 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_project_grade_category_train = pad_sequences(encoded_docs_project_grade_category_train, maxlen=max_length, padding='post')\n",
    "print(padded_docs_project_grade_category_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the flattened LSTM output for input text\n",
    "input_layer3 = Input(shape=(max_length,))\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=5, input_length=max_length, trainable=True)(input_layer3)\n",
    "flatten_project_grade_category = Flatten()(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_project_grade_category_test=list(X_test.project_grade_category.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_project_grade_category_test)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_project_grade_category_test = tokens.texts_to_sequences(docs_project_grade_category_test)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 ... 0 0 0]\n",
      " [1 4 5 ... 0 0 0]\n",
      " [1 4 5 ... 0 0 0]\n",
      " ...\n",
      " [1 4 5 ... 0 0 0]\n",
      " [1 6 7 ... 0 0 0]\n",
      " [1 2 3 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_project_grade_category_test = pad_sequences(encoded_docs_project_grade_category_test, maxlen=max_length, padding='post')\n",
    "print(padded_docs_project_grade_category_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: clean_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_clean_categories_train=list(X_train.clean_categories.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_clean_categories_train)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_clean_categories_train = tokens.texts_to_sequences(docs_clean_categories_train)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "all_lengths=[]\n",
    "for sent in encoded_docs_clean_categories_train:\n",
    "    length=len(sent)\n",
    "    all_lengths.append(length)\n",
    "print(max(all_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 0 0 0]\n",
      " [5 6 0 0 0]\n",
      " [1 2 3 4 0]\n",
      " ...\n",
      " [3 4 0 0 0]\n",
      " [3 4 0 0 0]\n",
      " [1 2 3 4 0]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_clean_categories_train = pad_sequences(encoded_docs_clean_categories_train, maxlen=max_length, padding='post')\n",
    "print(padded_docs_clean_categories_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the flattened LSTM output for input text\n",
    "input_layer4 = Input(shape=(max_length,))\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=5, input_length=max_length, trainable=True)(input_layer4)\n",
    "flatten_clean_categories = Flatten()(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_clean_categories_test=list(X_test.clean_categories.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_clean_categories_test)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_clean_categories_test = tokens.texts_to_sequences(docs_clean_categories_test)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2 11 12  0]\n",
      " [ 1  2  3  4  0]\n",
      " [ 7  8  0  0  0]\n",
      " ...\n",
      " [ 5  6  0  0  0]\n",
      " [ 5  6  0  0  0]\n",
      " [ 1  2  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_clean_categories_test = pad_sequences(encoded_docs_clean_categories_test, maxlen=max_length, padding='post')\n",
    "print(padded_docs_clean_categories_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: clean_subcategories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_clean_subcategories_train=list(X_train.clean_subcategories.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_clean_subcategories_train)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_clean_subcategories_train = tokens.texts_to_sequences(docs_clean_subcategories_train)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "all_lengths=[]\n",
    "for sent in encoded_docs_clean_subcategories_train:\n",
    "    length=len(sent)\n",
    "    all_lengths.append(length)\n",
    "print(max(all_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  4  0  0  0]\n",
      " [ 5 10  0  0  0  0]\n",
      " [ 3  4  2  0  0  0]\n",
      " ...\n",
      " [ 9  8  2  0  0  0]\n",
      " [ 5 20 11  2  0  0]\n",
      " [ 1  2  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_clean_subcategories_train = pad_sequences(encoded_docs_clean_subcategories_train, maxlen=max_length, padding='post')\n",
    "print(padded_docs_clean_subcategories_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the flattened LSTM output for input text\n",
    "input_layer5 = Input(shape=(max_length,))\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=5, input_length=max_length, trainable=True)(input_layer5)\n",
    "flatten_clean_subcategories = Flatten()(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_clean_subcategories_test=list(X_test.clean_subcategories.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_clean_subcategories_test)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_clean_subcategories_test = tokens.texts_to_sequences(docs_clean_subcategories_test)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 13 12  0  0  0]\n",
      " [ 3  4  2  0  0  0]\n",
      " [ 6  7  0  0  0  0]\n",
      " ...\n",
      " [ 5 10 34 21  0  0]\n",
      " [ 5 10  0  0  0  0]\n",
      " [ 1  3  4  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_clean_subcategories_test = pad_sequences(encoded_docs_clean_subcategories_test, maxlen=max_length, padding='post')\n",
    "print(padded_docs_clean_subcategories_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data: teacher_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_teacher_prefix_train=list(X_train.teacher_prefix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_teacher_prefix_train)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_teacher_prefix_train = tokens.texts_to_sequences(docs_teacher_prefix_train)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "all_lengths=[]\n",
    "for sent in encoded_docs_teacher_prefix_train:\n",
    "    length=len(sent)\n",
    "    all_lengths.append(length)\n",
    "print(max(all_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_teacher_prefix_train = pad_sequences(encoded_docs_teacher_prefix_train, maxlen=max_length, padding='post')\n",
    "#print(padded_docs_teacher_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the flattened LSTM output for input text\n",
    "input_layer6 = Input(shape=(max_length,))\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=5, input_length=max_length, trainable=True)(input_layer6)\n",
    "flatten_teacher_prefix = Flatten()(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_teacher_prefix_test=list(X_test.teacher_prefix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "#Prepare tokenizer\n",
    "tokens = Tokenizer()\n",
    "tokens.fit_on_texts(docs_teacher_prefix_test)\n",
    "vocab_size = len(tokens.word_index) + 1\n",
    "#Integer encode the documents\n",
    "encoded_docs_teacher_prefix_test = tokens.texts_to_sequences(docs_teacher_prefix_test)\n",
    "#print(encoded_docs)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = max(all_lengths)\n",
    "padded_docs_teacher_prefix_test = pad_sequences(encoded_docs_teacher_prefix_test, maxlen=max_length, padding='post')\n",
    "#print(padded_docs_teacher_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## teacher_number_of_previously_posted_projects, nrm_price, presence_of_the_numerical_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>presence_of_the_numerical_digits</th>\n",
       "      <th>nrm_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12257</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15921</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61791</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       teacher_number_of_previously_posted_projects  \\\n",
       "6013                                              0   \n",
       "12257                                            14   \n",
       "15921                                             1   \n",
       "61791                                             1   \n",
       "99000                                             0   \n",
       "\n",
       "       presence_of_the_numerical_digits  nrm_price  \n",
       "6013                                  0   0.024906  \n",
       "12257                                 0   0.012119  \n",
       "15921                                 0   0.013512  \n",
       "61791                                 0   0.003934  \n",
       "99000                                 0   0.014935  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df_train=X_train[['teacher_number_of_previously_posted_projects','presence_of_the_numerical_digits','nrm_price']]\n",
    "numerical_df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dense layer\n",
    "input_layer7 = Input(shape=(3,))\n",
    "dense_layer = Dense(3, activation='relu')(input_layer7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>presence_of_the_numerical_digits</th>\n",
       "      <th>nrm_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60773</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.079946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49967</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45133</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106907</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100838</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        teacher_number_of_previously_posted_projects  \\\n",
       "60773                                              2   \n",
       "49967                                              0   \n",
       "45133                                              1   \n",
       "106907                                            26   \n",
       "100838                                             3   \n",
       "\n",
       "        presence_of_the_numerical_digits  nrm_price  \n",
       "60773                                  0   0.079946  \n",
       "49967                                  0   0.014935  \n",
       "45133                                  0   0.037735  \n",
       "106907                                 1   0.010642  \n",
       "100838                                 0   0.011325  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df_test=X_test[['teacher_number_of_previously_posted_projects','presence_of_the_numerical_digits','nrm_price']]\n",
    "numerical_df_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation of all the layers and building the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "x = concatenate([flatten_lstm_out, flatten_school_state, flatten_project_grade_category, flatten_clean_categories, flatten_clean_subcategories, flatten_teacher_prefix, dense_layer])\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "output = Dense(1, activation='softmax', name='output1')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a custom metric AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#https://datascience.stackexchange.com/questions/13746/how-to-define-a-custom-performance-metric-in-keras/20192#20192\\nimport keras\\nimport numpy as np\\nimport sklearn.metrics as sklm\\n\\n\\nclass Metrics(keras.callbacks.Callback):\\n    def on_train_begin(self, logs={}):\\n        self.auc = []\\n\\n    def on_epoch_end(self, epoch, logs={}):\\n        score = np.asarray(self.model.predict(self.validation_data[0]))\\n        print(\"Score:\", score)\\n        predict = np.round(np.asarray(self.model.predict(self.validation_data[0])))\\n        print(\"predict:\", predict)\\n        targ = self.validation_data[1]\\n\\n        self.auc.append(sklm.roc_auc_score(targ, predict))\\n        return\\n    \\nmetrics = Metrics()\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#https://datascience.stackexchange.com/questions/13746/how-to-define-a-custom-performance-metric-in-keras/20192#20192\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "\n",
    "class Metrics(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.auc = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        score = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        print(\"Score:\", score)\n",
    "        predict = np.round(np.asarray(self.model.predict(self.validation_data[0])))\n",
    "        print(\"predict:\", predict)\n",
    "        targ = self.validation_data[1]\n",
    "\n",
    "        self.auc.append(sklm.roc_auc_score(targ, predict))\n",
    "        return\n",
    "    \n",
    "metrics = Metrics()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as sklm\n",
    "import tensorflow as tf\n",
    "def auc_roc(y_true, y_pred):\n",
    "    try:\n",
    "        return tf.py_func(sklm.roc_auc_score, (y_true, y_pred), tf.double)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a TensorBoard callback object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-58-db88660b5ed6>:5: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 87398 samples, validate on 21850 samples\n",
      "Epoch 1/10\n",
      "87398/87398 [==============================] - 537s 6ms/step - loss: 2.4140 - acc: 0.8486 - auc_roc: 0.5000 - val_loss: 2.4136 - val_acc: 0.8486 - val_auc_roc: 0.5000\n",
      "Epoch 2/10\n",
      "87398/87398 [==============================] - 544s 6ms/step - loss: 2.4140 - acc: 0.8486 - auc_roc: 0.5000 - val_loss: 2.4136 - val_acc: 0.8486 - val_auc_roc: 0.5000\n",
      "Epoch 3/10\n",
      "87398/87398 [==============================] - 563s 6ms/step - loss: 2.4140 - acc: 0.8486 - auc_roc: 0.5000 - val_loss: 2.4136 - val_acc: 0.8486 - val_auc_roc: 0.5000\n",
      "Epoch 4/10\n",
      "87398/87398 [==============================] - 565s 6ms/step - loss: 2.4140 - acc: 0.8486 - auc_roc: 0.5000 - val_loss: 2.4136 - val_acc: 0.8486 - val_auc_roc: 0.5000\n",
      "Epoch 5/10\n",
      "87398/87398 [==============================] - 564s 6ms/step - loss: 2.4140 - acc: 0.8486 - auc_roc: 0.5000 - val_loss: 2.4136 - val_acc: 0.8486 - val_auc_roc: 0.5000\n",
      "Epoch 6/10\n",
      "87398/87398 [==============================] - 567s 6ms/step - loss: 2.4140 - acc: 0.8486 - auc_roc: 0.5000 - val_loss: 2.4136 - val_acc: 0.8486 - val_auc_roc: 0.5000\n",
      "Epoch 7/10\n",
      "87398/87398 [==============================] - 567s 6ms/step - loss: 2.4140 - acc: 0.8486 - auc_roc: 0.5000 - val_loss: 2.4136 - val_acc: 0.8486 - val_auc_roc: 0.5000\n",
      "Epoch 8/10\n",
      "87398/87398 [==============================] - 566s 6ms/step - loss: 2.4140 - acc: 0.8486 - auc_roc: 0.5000 - val_loss: 2.4136 - val_acc: 0.8486 - val_auc_roc: 0.5000\n",
      "Epoch 9/10\n",
      "87398/87398 [==============================] - 564s 6ms/step - loss: 2.4140 - acc: 0.8486 - auc_roc: 0.5000 - val_loss: 2.4136 - val_acc: 0.8486 - val_auc_roc: 0.5000\n",
      "Epoch 10/10\n",
      "87398/87398 [==============================] - 570s 7ms/step - loss: 2.4140 - acc: 0.8486 - auc_roc: 0.5000 - val_loss: 2.4136 - val_acc: 0.8486 - val_auc_roc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f59162ca908>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputs=[input_layer1,input_layer2,input_layer3,input_layer4,input_layer5,input_layer6,input_layer7], outputs=output)\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy',auc_roc])\n",
    "model.fit(x=[padded_docs_essay_train, padded_docs_school_state_train, padded_docs_project_grade_category_train, padded_docs_clean_categories_train, padded_docs_clean_subcategories_train, padded_docs_teacher_prefix_train, numerical_df_train], \n",
    "          y=[labels_train],\n",
    "          validation_data=([padded_docs_essay_test, padded_docs_school_state_test, padded_docs_project_grade_category_test, padded_docs_clean_categories_test, padded_docs_clean_subcategories_test, padded_docs_teacher_prefix_test, numerical_df_test],[labels_test]),\n",
    "          epochs=10, \n",
    "          batch_size=64, \n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0726 23:12:59.097108 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.111174 139700309554944 plugin_event_accumulator.py:302] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0726 23:12:59.143583 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.155557 139700309554944 plugin_event_accumulator.py:302] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0726 23:12:59.190407 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.239963 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.255520 139700309554944 plugin_event_accumulator.py:302] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "TensorBoard 1.13.1 at http://saugata:6006 (Press CTRL+C to quit)\n",
      "W0726 23:12:59.301306 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.325635 139700309554944 plugin_event_accumulator.py:302] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0726 23:12:59.363682 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.382292 139700309554944 plugin_event_accumulator.py:302] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0726 23:12:59.406032 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.407257 139700309554944 plugin_event_accumulator.py:302] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0726 23:12:59.435978 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.437082 139700309554944 plugin_event_accumulator.py:302] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0726 23:12:59.456918 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.458396 139700309554944 plugin_event_accumulator.py:302] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0726 23:12:59.487738 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.518584 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.558245 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.563189 139700309554944 plugin_event_accumulator.py:302] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0726 23:12:59.610628 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.615735 139700309554944 plugin_event_accumulator.py:302] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0726 23:12:59.639674 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.641485 139700309554944 plugin_event_accumulator.py:302] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "W0726 23:12:59.668507 139700309554944 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0726 23:12:59.669562 139700309554944 plugin_event_accumulator.py:302] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='screenshot.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\nTraceback (most recent call last):\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 207, in __call__\n    ret = func(*args)\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\", line 356, in roc_auc_score\n    sample_weight=sample_weight)\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/base.py\", line 77, in _average_binary_score\n    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\", line 324, in _binary_roc_auc_score\n    raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n\n\n\t [[{{node metrics/auc_roc/PyFunc}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-8caa044dc74d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m loss, accuracy = model.evaluate([padded_docs_essay_test, padded_docs_school_state_test, padded_docs_project_grade_category_test, padded_docs_clean_categories_test, padded_docs_clean_subcategories_test, padded_docs_teacher_prefix_test, numerical_df_test],\n\u001b[0;32m----> 2\u001b[0;31m [labels_test], verbose=0)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                                          steps=steps)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\nTraceback (most recent call last):\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 207, in __call__\n    ret = func(*args)\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\", line 356, in roc_auc_score\n    sample_weight=sample_weight)\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/base.py\", line 77, in _average_binary_score\n    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\", line 324, in _binary_roc_auc_score\n    raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n\n\n\t [[{{node metrics/auc_roc/PyFunc}}]]"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate([padded_docs_essay_test, padded_docs_school_state_test, padded_docs_project_grade_category_test, padded_docs_clean_categories_test, padded_docs_clean_subcategories_test, padded_docs_teacher_prefix_test, numerical_df_test],\n",
    "[labels_test], verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(x=[padded_docs_essay_test, padded_docs_school_state_test, padded_docs_project_grade_category_test, padded_docs_clean_categories_test, padded_docs_clean_subcategories_test, padded_docs_teacher_prefix_test, numerical_df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=predictions.shape[0]\n",
    "y_pred=[]\n",
    "for i in range(limit):\n",
    "    if(predictions[i][0]<0.5):\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "acc_score=metrics.accuracy_score(y_test,y_pred)\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "auc_score=metrics.roc_auc_score(y_test,y_pred)\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "[>                                                           ] 0%\r",
      "[======>                                                     ] 11%\r",
      "Warning: Failed to load file:///mnt/0AD801EDD801D7B9/Donors Assignment/LSTM-for-Donors/custom.css (ignore)\n",
      "[===========================>                                ] 45%\r",
      "[=============================>                              ] 49%\r",
      "[=================================>                          ] 55%\r",
      "[============================================================] 100%\r",
      "Printing pages (2/2)                                               \n",
      "[>                                                           ] \r",
      "Done                                                           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfkit\n",
    "pdfkit.from_file('Test Pad - Model 1.html', 'Test Pad - Model 1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-5d46d32f565b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    354\u001b[0m     return _average_binary_score(\n\u001b[1;32m    355\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    325\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_true = np.array([0, 0, 0, 0])\n",
    "y_scores = np.array([1, 0, 0, 0])\n",
    "roc_auc_score(y_true, y_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
